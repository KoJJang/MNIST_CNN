{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-a839aeb82f4b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float32, [None,784])\n",
    "input_reshaped = tf.reshape(inputs, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_weights = tf.Variable(tf.truncated_normal([5,5,1,8], stddev=0.1))\n",
    "conv1_bias = tf.Variable(tf.zeros([8]))\n",
    "conv1 = tf.nn.conv2d(input_reshaped, conv1_weights, strides=[1,1,1,1], padding='SAME')\n",
    "conv1_relu = tf.nn.relu(conv1 + conv1_bias)\n",
    "\n",
    "max_pool1 = tf.nn.max_pool(conv1_relu, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_output = tf.reshape(max_pool2, [-1, 7*7*16])\n",
    "\n",
    "fully_connected_weights = tf.Variable(tf.truncated_normal([7*7*16, 128], stddev=0.1))\n",
    "fully_connected_bias = tf.Variable(tf.zeros([128]))\n",
    "fully_connected = tf.nn.relu(tf.matmul(flat_output, fully_connected_weights) + fully_connected_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_weights =tf.Variable(tf.truncated_normal([128, 10], stddev=0.1))\n",
    "output_bias = tf.Variable(tf.zeros([10]))\n",
    "output_layer = tf.nn.softmax(tf.matmul(fully_connected, output_weights) + output_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = tf.placeholder(tf.float32, [None,10])\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(label_data* tf.log(output_layer), reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(output_layer,1), tf.argmax(label_data,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training ACC 0.160\n",
      "step 100, training ACC 0.880\n",
      "step 200, training ACC 0.980\n",
      "step 300, training ACC 0.940\n",
      "step 400, training ACC 0.840\n",
      "step 500, training ACC 0.980\n",
      "step 600, training ACC 0.960\n",
      "step 700, training ACC 0.980\n",
      "step 800, training ACC 0.960\n",
      "step 900, training ACC 0.980\n",
      "step 1000, training ACC 0.980\n",
      "step 1100, training ACC 0.980\n",
      "step 1200, training ACC 0.980\n",
      "step 1300, training ACC 1.000\n",
      "step 1400, training ACC 1.000\n",
      "step 1500, training ACC 1.000\n",
      "step 1600, training ACC 0.980\n",
      "step 1700, training ACC 0.940\n",
      "step 1800, training ACC 1.000\n",
      "step 1900, training ACC 0.980\n",
      "step 2000, training ACC 0.940\n",
      "step 2100, training ACC 0.980\n",
      "step 2200, training ACC 0.980\n",
      "step 2300, training ACC 1.000\n",
      "step 2400, training ACC 0.980\n",
      "step 2500, training ACC 0.980\n",
      "step 2600, training ACC 0.960\n",
      "step 2700, training ACC 1.000\n",
      "step 2800, training ACC 0.960\n",
      "step 2900, training ACC 1.000\n",
      "step 3000, training ACC 0.960\n",
      "step 3100, training ACC 0.940\n",
      "step 3200, training ACC 0.960\n",
      "step 3300, training ACC 0.980\n",
      "step 3400, training ACC 0.960\n",
      "step 3500, training ACC 0.980\n",
      "step 3600, training ACC 0.980\n",
      "step 3700, training ACC 1.000\n",
      "step 3800, training ACC 1.000\n",
      "step 3900, training ACC 1.000\n",
      "step 4000, training ACC 1.000\n",
      "step 4100, training ACC 0.960\n",
      "step 4200, training ACC 0.980\n",
      "step 4300, training ACC 0.980\n",
      "step 4400, training ACC 0.980\n",
      "step 4500, training ACC 0.980\n",
      "step 4600, training ACC 0.980\n",
      "step 4700, training ACC 1.000\n",
      "step 4800, training ACC 0.980\n",
      "step 4900, training ACC 1.000\n",
      "step 5000, training ACC 1.000\n",
      "step 5100, training ACC 1.000\n",
      "step 5200, training ACC 1.000\n",
      "step 5300, training ACC 0.980\n",
      "step 5400, training ACC 1.000\n",
      "step 5500, training ACC 1.000\n",
      "step 5600, training ACC 0.960\n",
      "step 5700, training ACC 1.000\n",
      "step 5800, training ACC 0.980\n",
      "step 5900, training ACC 1.000\n",
      "step 6000, training ACC 1.000\n",
      "step 6100, training ACC 0.960\n",
      "step 6200, training ACC 1.000\n",
      "step 6300, training ACC 1.000\n",
      "step 6400, training ACC 1.000\n",
      "step 6500, training ACC 0.980\n",
      "step 6600, training ACC 1.000\n",
      "step 6700, training ACC 0.980\n",
      "step 6800, training ACC 1.000\n",
      "step 6900, training ACC 1.000\n",
      "step 7000, training ACC 1.000\n",
      "step 7100, training ACC 1.000\n",
      "step 7200, training ACC 0.980\n",
      "step 7300, training ACC 1.000\n",
      "step 7400, training ACC 1.000\n",
      "step 7500, training ACC 1.000\n",
      "step 7600, training ACC 1.000\n",
      "step 7700, training ACC 1.000\n",
      "step 7800, training ACC 0.980\n",
      "step 7900, training ACC 1.000\n",
      "step 8000, training ACC 0.980\n",
      "step 8100, training ACC 1.000\n",
      "step 8200, training ACC 1.000\n",
      "step 8300, training ACC 0.980\n",
      "step 8400, training ACC 0.980\n",
      "step 8500, training ACC 0.980\n",
      "step 8600, training ACC 1.000\n",
      "step 8700, training ACC 0.980\n",
      "step 8800, training ACC 1.000\n",
      "step 8900, training ACC 0.960\n",
      "step 9000, training ACC 1.000\n",
      "step 9100, training ACC 1.000\n",
      "step 9200, training ACC 1.000\n",
      "step 9300, training ACC 1.000\n",
      "step 9400, training ACC 1.000\n",
      "step 9500, training ACC 1.000\n",
      "step 9600, training ACC 1.000\n",
      "step 9700, training ACC 0.980\n",
      "step 9800, training ACC 1.000\n",
      "step 9900, training ACC 1.000\n",
      "test ACC 0.9891\n"
     ]
    }
   ],
   "source": [
    "####### Do Not Touch This Block.\n",
    "####### \"TEST\" accuracy of your CNN model have to be higher than 0.9 \n",
    "####### If your model have higher \"TEST\" accuracy than 0.95 you can get an additional point.\n",
    "####### If your model have higher \"TEST\" accuracy than 0.95 you can get an additional point.\n",
    "\n",
    "####### 이 블럭을 수정하지 마세요.\n",
    "####### 작성하신 모델의 \"TEST\" 정확도가 0.9 보다 높아야 합니다.\n",
    "####### 작성하신 모델의 \"TEST\" 정확도가 0.95 보다 높은 경우 추가 점수를 얻습니다.\n",
    "####### 작성하신 모델의 \"TEST\" 정확도가 0.98 보다 높은 경우 추가 점수를 얻습니다.\n",
    "for i in range(10000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(50)\n",
    "    if i%100 == 0:\n",
    "        pass\n",
    "        train_accuracy = accuracy.eval(session=sess, feed_dict={inputs:batch_xs, label_data: batch_ys})\n",
    "        print(\"step %d, training ACC %.3f\"%(i, train_accuracy))\n",
    "    sess.run(train_step, feed_dict={inputs:batch_xs, label_data: batch_ys})\n",
    "print(\"test ACC %g\"% accuracy.eval(session=sess, feed_dict={inputs: mnist.test.images, label_data:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
